{
  "goals": [
    "Provide an `nvst execute test-plan` command that runs all tests from an approved test plan via an agent",
    "Execute tests one by one, updating each test case's status (pass/fail) in a progress/results file",
    "Generate a summary report with pass/fail counts and details upon completion",
    "Follow the existing command patterns (skill invocation, progress tracking, state management)",
    "Support all agent providers (claude, codex, gemini)"
  ],
  "userStories": [
    {
      "id": "US-001",
      "title": "Execute Approved Test Plan",
      "description": "As a developer using the CLI, I want to run `nvst execute test-plan --agent <provider>` so that the agent executes all test cases from the approved test plan and I can track their results.",
      "acceptanceCriteria": [
        {
          "id": "US-001-AC01",
          "text": "Command fails with a descriptive error if the test plan has not been approved (i.e., `tp_generation.status` is not `\"created\"`)"
        },
        {
          "id": "US-001-AC02",
          "text": "Command reads the approved test plan JSON from the path in `state.phases.prototype.tp_generation.file`"
        },
        {
          "id": "US-001-AC03",
          "text": "Command reads the project context to follow project-specific execution constraints (test runner, environment, quality checks)"
        },
        {
          "id": "US-001-AC04",
          "text": "Command invokes the agent for each test case (automated and exploratory/manual) one by one"
        },
        {
          "id": "US-001-AC05",
          "text": "Execution order is verifiable: recorded executed test IDs match the source TP JSON order"
        },
        {
          "id": "US-001-AC06",
          "text": "Each test case execution attempt produces a structured result payload containing `status`, `evidence`, and `notes`; pass/fail is derived from payload status, while non-zero agent exit code is treated as invocation failure"
        },
        {
          "id": "US-001-AC07",
          "text": "Each test case execution attempt uses exactly one agent invocation and includes project-context reference in the invocation input"
        },
        {
          "id": "US-001-AC08",
          "text": "Command accepts `--agent <provider>` flag supporting `claude`, `codex`, and `gemini`"
        },
        {
          "id": "US-001-AC09",
          "text": "Typecheck / lint passes"
        }
      ]
    },
    {
      "id": "US-002",
      "title": "Track Per-Test-Case Progress",
      "description": "As a developer, I want each test case's execution status to be persisted to a progress file so that I can resume or review test execution at any time.",
      "acceptanceCriteria": [
        {
          "id": "US-002-AC01",
          "text": "A progress file `it_{iteration}_test-execution-progress.json` is created/updated in `.agents/flow/`"
        },
        {
          "id": "US-002-AC02",
          "text": "Each test case entry includes: `id`, `type` (automated | exploratory_manual), `status` (pending | in_progress | passed | failed), `attempt_count`, `last_agent_exit_code`, `last_error_summary`, `updated_at`"
        },
        {
          "id": "US-002-AC03",
          "text": "Progress file is updated after each test case execution attempt"
        },
        {
          "id": "US-002-AC04",
          "text": "If the command is re-run, it resumes from pending/failed test cases (does not re-execute passed tests)"
        },
        {
          "id": "US-002-AC05",
          "text": "Typecheck / lint passes"
        }
      ]
    },
    {
      "id": "US-003",
      "title": "Update State on Execution",
      "description": "As a developer, I want `state.json` to reflect the test execution status so that the workflow state is consistent with the rest of the CLI.",
      "acceptanceCriteria": [
        {
          "id": "US-003-AC01",
          "text": "A new `test_execution` field is added to the prototype phase in the state schema with `status` (`pending` | `in_progress` | `completed` | `failed`) and `file` (path to progress file)"
        },
        {
          "id": "US-003-AC02",
          "text": "State is set to `in_progress` when execution begins"
        },
        {
          "id": "US-003-AC03",
          "text": "State is set to `completed` when all test cases pass"
        },
        {
          "id": "US-003-AC04",
          "text": "State is set to `failed` if any test cases remain in `failed` status after execution completes"
        },
        {
          "id": "US-003-AC05",
          "text": "Typecheck / lint passes"
        }
      ]
    },
    {
      "id": "US-004",
      "title": "Generate Test Execution Summary Report",
      "description": "As a developer, I want a summary report printed to the console and saved to a file after execution completes so that I can quickly assess the test results.",
      "acceptanceCriteria": [
        {
          "id": "US-004-AC01",
          "text": "A summary report file `it_{iteration}_test-execution-report.md` is written to `.agents/flow/`"
        },
        {
          "id": "US-004-AC02",
          "text": "Report includes: total tests, passed count, failed count, and a table with per-test-case results (id, description, status, correlated requirements)"
        },
        {
          "id": "US-004-AC03",
          "text": "A concise summary is printed to stdout upon completion (e.g., \"12/15 tests passed, 3 failed\")"
        },
        {
          "id": "US-004-AC04",
          "text": "Per-test raw execution artifacts are persisted in `.agents/flow/it_{iteration}_test-execution-artifacts/` and each test case result includes references to its stored artifacts"
        },
        {
          "id": "US-004-AC05",
          "text": "Typecheck / lint passes"
        }
      ]
    },
    {
      "id": "US-005",
      "title": "Create Agent Skill for Test Execution",
      "description": "As a developer, I want a dedicated skill prompt that guides the agent to execute a single test case so that the agent has clear instructions for running and verifying each test.",
      "acceptanceCriteria": [
        {
          "id": "US-005-AC01",
          "text": "A new skill `execute-test-case` is created in `.agents/skills/execute-test-case/SKILL.md`"
        },
        {
          "id": "US-005-AC02",
          "text": "The skill prompt instructs the agent to: read the test case definition, execute it following project context constraints, report pass/fail with details"
        },
        {
          "id": "US-005-AC03",
          "text": "The skill is loaded and used by the `execute test-plan` command for each test case invocation"
        },
        {
          "id": "US-005-AC04",
          "text": "Typecheck / lint passes"
        }
      ]
    }
  ],
  "functionalRequirements": [
    {
      "id": "FR-1",
      "description": "The command signature is `nvst execute test-plan --agent <provider>` where provider is `claude | codex | gemini`"
    },
    {
      "id": "FR-2",
      "description": "The command validates that `tp_generation.status === \"created\"` before proceeding; otherwise exits with an error"
    },
    {
      "id": "FR-3",
      "description": "The command reads the approved TP JSON file and the project context file to build the execution context"
    },
    {
      "id": "FR-4",
      "description": "Automated tests and exploratory/manual tests are executed sequentially, one by one, following the order in the TP JSON"
    },
    {
      "id": "FR-5",
      "description": "For each test case, the command loads the `execute-test-case` skill, builds a prompt with test case details and project context, and invokes the agent"
    },
    {
      "id": "FR-6",
      "description": "After each test case, the command parses a structured result payload (`status`, `evidence`, `notes`) to determine pass/fail, and treats non-zero agent exit code as invocation failure"
    },
    {
      "id": "FR-7",
      "description": "The progress file follows the schema `test-execution-progress` and is validated via `write-json`"
    },
    {
      "id": "FR-8",
      "description": "On completion, a markdown summary report is generated with total, passed, and failed counts, and the state is updated to `completed` or `failed`"
    },
    {
      "id": "FR-9",
      "description": "Re-running the command skips test cases already marked as `passed` and retries `pending` or `failed` ones"
    },
    {
      "id": "FR-10",
      "description": "The command follows the existing command implementation pattern: read state, validate preconditions, load skill, invoke agent per item, update progress, update state"
    },
    {
      "id": "FR-11",
      "description": "The command persists per-test raw execution artifacts under `.agents/flow/it_{iteration}_test-execution-artifacts/` and stores artifact references in execution results"
    }
  ]
}
